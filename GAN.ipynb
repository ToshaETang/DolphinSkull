{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f12d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存生成器和判别器的權重\n",
    "#generator.save_weights('generator_weights.h5')\n",
    "#discriminator.save_weights('discriminator_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83780d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7405f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ba988e0",
   "metadata": {},
   "source": [
    "# 灰度轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d674f78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "灰度轉換完成\n"
     ]
    }
   ],
   "source": [
    "# pip install opencv-python\n",
    "# pip install opencv-python --upgrade\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# 指定原始彩色圖像文件夾和目標灰度圖像文件夾\n",
    "original_folder = r'C:\\Users\\Tosha.E.T\\Documents\\GitHub\\DolphinSkull\\2022-3-8'\n",
    "gray_folder = r'C:\\Users\\Tosha.E.T\\Documents\\GitHub\\DolphinSkull\\2022-3-8\\gray\\class_1'\n",
    "\n",
    "# 確保目標文件夾存在\n",
    "if not os.path.exists(gray_folder):\n",
    "    os.makedirs(gray_folder)\n",
    "\n",
    "# 遍歷原始文件夾中的每個圖像\n",
    "for filename in os.listdir(original_folder):\n",
    "    if filename.endswith('.JPG'):\n",
    "        # 讀取原始圖像\n",
    "        original_image_path = os.path.join(original_folder, filename)\n",
    "        original_image = cv2.imread(original_image_path)\n",
    "\n",
    "        # 將彩色圖像轉換為灰度圖像\n",
    "        gray_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # 保存灰度圖像到目標文件夾\n",
    "        gray_image_path = os.path.join(gray_folder, filename)\n",
    "        cv2.imwrite(gray_image_path, gray_image)\n",
    "\n",
    "print(\"灰度轉換完成\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0b847a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2340c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "242f26af",
   "metadata": {},
   "source": [
    "# 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01a5adcc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 169 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# pip install --upgrade protobuf\n",
    "# pip install protobuf==3.20.0\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Reshape, Flatten\n",
    "from keras.layers import Conv2D, Conv2DTranspose, LeakyReLU, BatchNormalization, Input\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def build_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128 * 7 * 7, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(1, (7, 7), activation='sigmoid', padding='same'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_discriminator(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=(28, 28, 1)))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    return model\n",
    "\n",
    "\n",
    "latent_dim = 100\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "\n",
    "discriminator = build_discriminator(input_shape)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "generator = build_generator(latent_dim)\n",
    "\n",
    "discriminator.trainable = False\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "\n",
    "# 定义图像数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 通过图像数据生成器加载训练数据\n",
    "batch_size = 16\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    r'C:\\Users\\Tosha.E.T\\Documents\\GitHub\\DolphinSkull\\2022-3-8\\gray',  \n",
    "    target_size=(28, 28),     \n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "\n",
    "epochs = 100  # 你可以根据需要设置训练的轮数\n",
    "# 训练GAN模型\n",
    "for epoch in range(epochs):\n",
    "    # 生成潜在噪声\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    \n",
    "    # 使用生成器生成假影像\n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    # 从数据生成器中获取一批真实影像\n",
    "    real_images, labels_real = train_generator.next()\n",
    "    \n",
    "    # print(generated_images)\n",
    "\n",
    "    # 进行判别器和生成器的训练\n",
    "    d_loss_real = discriminator.train_on_batch(real_images, labels_real)\n",
    "    labels_fake = np.zeros((batch_size, 1))  # 添加缺失的 labels_fake\n",
    "    d_loss_fake = discriminator.train_on_batch(generated_images, labels_fake)\n",
    "\n",
    "    # 修改生成器的輸出形狀\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    generated_images = generator.predict(noise)\n",
    "    labels_fake = np.zeros((batch_size, 1))  # 添加缺失的 labels_fake\n",
    "\n",
    "    # 重新進行判别器和生成器的訓練\n",
    "    d_loss_real = discriminator.train_on_batch(real_images, labels_real)\n",
    "    d_loss_fake = discriminator.train_on_batch(generated_images, labels_fake)\n",
    "\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    labels_gan = np.ones((batch_size, 1))\n",
    "\n",
    "    g_loss = gan.train_on_batch(noise, labels_gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b131fa4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7aef3ffa",
   "metadata": {},
   "source": [
    "# 顯示假的影像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e56f9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成潛在噪聲\n",
    "noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "\n",
    "# 使用生成器生成假影像\n",
    "generated_images = generator.predict(noise)\n",
    "\n",
    "# 將生成的假影像顯示出來\n",
    "rows, columns = 4, 4  # 設定顯示的行列數\n",
    "fig, axs = plt.subplots(rows, columns)\n",
    "\n",
    "# 將每個生成的影像放入子圖\n",
    "for i in range(rows):\n",
    "    for j in range(columns):\n",
    "        axs[i, j].imshow(generated_images[i * columns + j, :, :, 0], cmap='gray')\n",
    "        axs[i, j].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047280c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
